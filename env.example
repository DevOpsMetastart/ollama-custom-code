# Ollama Server Configuration
OLLAMA_BASE_URL=your-llm-hosted-url
OLLAMA_TIMEOUT=30000
OLLAMA_MAX_RETRIES=3

# API Server Configuration
PORT=3000
NODE_ENV=development

# Security
API_KEY=your-secret-api-key-here
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# Logging
LOG_LEVEL=info
LOG_FILE=logs/app.log

# CORS
# For Railway deployment, you can either:
# 1. Set NODE_ENV=production to allow all origins (less secure but easier)
# 2. Set specific allowed origins for your frontend domains
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001,https://your-frontend-domain.com
# For Railway, you might want to add your Railway app URL:
# ALLOWED_ORIGINS=http://localhost:3000,https://your-app-name.railway.app

# Model Configuration
DEFAULT_MODEL=llama2
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=2048
