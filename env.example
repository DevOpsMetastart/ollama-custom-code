# Ollama Server Configuration
OLLAMA_BASE_URL=your-llm-hosted-url
OLLAMA_API_KEY=your-ollama-api-key
OLLAMA_TIMEOUT=30000
OLLAMA_MAX_RETRIES=3

# API Server Configuration
PORT=3000
NODE_ENV=development

# Security
API_KEY=your-secret-api-key-here
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# Logging
LOG_LEVEL=info
LOG_FILE=logs/app.log

# CORS Configuration
# For Railway deployment, set NODE_ENV=production to allow all origins
# For restricted access, set specific allowed origins:
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001,https://your-frontend-domain.com
# Railway deployment example:
# ALLOWED_ORIGINS=http://localhost:3000,https://your-app-name.railway.app

# Model Configuration
DEFAULT_MODEL=llama2
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=2048
WHISPER_MODEL_NAME=small.en
