# Ollama Server Configuration
OLLAMA_BASE_URL=https://erccjfczbqn5gr-11434.proxy.runpod.net
OLLAMA_TIMEOUT=30000
OLLAMA_MAX_RETRIES=3

# API Server Configuration
PORT=3000
NODE_ENV=development

# Security
API_KEY=your-secret-api-key-here
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# Logging
LOG_LEVEL=info
LOG_FILE=logs/app.log

# CORS
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001

# Model Configuration
DEFAULT_MODEL=llama2
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=2048
